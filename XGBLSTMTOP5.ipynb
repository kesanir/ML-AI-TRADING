{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUofX5p84t36jB6HBWgJvK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw2as5ox7F-J"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NASDAQ-100 MOMENTUM: XGBoost + LSTM ENSEMBLE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class Config:\n",
        "    # Data\n",
        "    TRAIN_YEARS = 4\n",
        "    LOOKBACK_LSTM = 30  # Days for LSTM\n",
        "    LOOKBACK_XGBOOST = 1  # Forward return target for XGBoost\n",
        "\n",
        "    # Model selection\n",
        "    USE_XGBOOST = True\n",
        "    USE_LSTM = True\n",
        "    ENSEMBLE_WEIGHT_XGB = 0.6  # 60% XGBoost, 40% LSTM\n",
        "    ENSEMBLE_WEIGHT_LSTM = 0.4\n",
        "\n",
        "    # Portfolio\n",
        "    TOP_N = 10\n",
        "    #MIN_CONFIDENCE = 0.55\n",
        "    MIN_CONFIDENCE = 0.50\n",
        "    # Validation\n",
        "    TEST_DAYS = 60  # Hold-out period\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# ============================================================================\n",
        "# TICKERS\n",
        "# ============================================================================\n",
        "\n",
        "TICKERS = [\n",
        "    'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA', 'AVGO',\n",
        "    'COST', 'NFLX', 'ADBE', 'PEP', 'CSCO', 'TMUS', 'AMD', 'INTC',\n",
        "    'CMCSA', 'INTU', 'QCOM', 'TXN', 'AMGN', 'HON', 'AMAT', 'SBUX',\n",
        "    'ISRG', 'BKNG', 'GILD', 'ADI', 'ADP', 'VRTX', 'MDLZ', 'LRCX',\n",
        "    'REGN', 'MU', 'PANW', 'PYPL', 'SNPS', 'CDNS', 'KLAC', 'ASML',\n",
        "    'MELI', 'CRWD', 'ABNB', 'FTNT', 'WDAY', 'MRNA', 'CTAS', 'DXCM',\n",
        "    'ORLY', 'AEP', 'NXPI', 'CHTR', 'MAR', 'ADSK', 'MCHP', 'KDP',\n",
        "    'MNST', 'EXC', 'ROST', 'CSX', 'KHC', 'PCAR', 'PAYX', 'CPRT',\n",
        "    'AZN', 'CSGP', 'ODFL', 'DDOG', 'FAST', 'BKR', 'TTD', 'CTSH',\n",
        "    'EA', 'GEHC', 'VRSK', 'LULU', 'ON', 'XEL', 'IDXX', 'ZS','S',\n",
        "    'CCEP', 'TEAM', 'FANG', 'BIIB', 'CDW', 'ILMN', 'DASH',\n",
        "    'GFS', 'WBD', 'MRVL', 'TTWO', 'EBAY', 'ZM', 'ALGN', 'ENPH'\n",
        "    ]\n",
        "\n",
        "print(f\"Universe: {len(TICKERS)} stocks\")\n",
        "\n",
        "# ============================================================================\n",
        "# 1. DOWNLOAD DATA\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nDownloading data...\")\n",
        "data = yf.download(\n",
        "    TICKERS + [\"QQQ\", \"^VIX\"],\n",
        "    period=f\"{config.TRAIN_YEARS}y\",\n",
        "    auto_adjust=True,\n",
        "    progress=False\n",
        ")\n",
        "\n",
        "close = data[\"Close\"]\n",
        "high = data[\"High\"]\n",
        "low = data[\"Low\"]\n",
        "volume = data[\"Volume\"]\n",
        "\n",
        "qqq = close[\"QQQ\"]\n",
        "vix = close[\"^VIX\"]\n",
        "\n",
        "print(f\"‚úÖ Downloaded {len(close)} days of data\")\n",
        "\n",
        "# ============================================================================\n",
        "# 2. REGIME DETECTION\n",
        "# ============================================================================\n",
        "\n",
        "qqq_200 = qqq.rolling(200).mean()\n",
        "ma_distance = (qqq - qqq_200) / qqq_200\n",
        "ma_distance_smooth = ma_distance.rolling(5).mean()\n",
        "regime = (ma_distance_smooth > 0).astype(int).shift(1)\n",
        "\n",
        "current_regime = \"üöÄ BULL\" if regime.iloc[-1] == 1 else \"üêª BEAR\"\n",
        "print(f\"Current Regime: {current_regime}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 3. FEATURE ENGINEERING FOR XGBOOST\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nBuilding feature panel for XGBoost...\")\n",
        "\n",
        "feature_list = []\n",
        "\n",
        "for t in TICKERS:\n",
        "    df = pd.DataFrame(index=close.index)\n",
        "    df[\"Ticker\"] = t\n",
        "    df[\"Close\"] = close[t]\n",
        "\n",
        "    # Price features\n",
        "    df[\"Returns\"] = close[t].pct_change()\n",
        "    df[\"ROC_5\"] = close[t].pct_change(5)\n",
        "    df[\"ROC_20\"] = close[t].pct_change(20)\n",
        "\n",
        "    # Volatility\n",
        "    tr = pd.concat([\n",
        "        high[t] - low[t],\n",
        "        (high[t] - close[t].shift()).abs(),\n",
        "        (low[t] - close[t].shift()).abs()\n",
        "    ], axis=1).max(axis=1)\n",
        "    df[\"ATR\"] = tr.rolling(14).mean() / close[t]\n",
        "\n",
        "    # RSI\n",
        "    delta = close[t].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
        "    rs = gain / (loss + 1e-10)\n",
        "    df[\"RSI\"] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Volume\n",
        "    df[\"Volume_MA\"] = volume[t].rolling(20).mean()\n",
        "    df[\"Volume_Ratio\"] = volume[t] / df[\"Volume_MA\"]\n",
        "\n",
        "    # Market features\n",
        "    df[\"VIX\"] = vix\n",
        "    df[\"VIX_Change\"] = vix.pct_change(10)\n",
        "    df[\"Regime\"] = regime\n",
        "\n",
        "    # TARGET: Forward 21-day return (for XGBoost)\n",
        "    df[\"Fwd_Return_21d\"] = close[t].pct_change(config.LOOKBACK_XGBOOST).shift(-config.LOOKBACK_XGBOOST)\n",
        "\n",
        "    feature_list.append(df)\n",
        "\n",
        "panel = pd.concat(feature_list)\n",
        "panel = panel.dropna()\n",
        "\n",
        "print(f\"‚úÖ Panel created: {len(panel)} observations\")\n",
        "\n",
        "# ============================================================================\n",
        "# 4. CROSS-SECTIONAL Z-SCORING (KEY FOR XGBOOST)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"Applying cross-sectional z-scoring...\")\n",
        "\n",
        "feature_cols = [\"Returns\", \"ROC_5\", \"ROC_20\", \"ATR\", \"RSI\", \"Volume_Ratio\", \"VIX\", \"VIX_Change\"]\n",
        "\n",
        "def zscore_transform(x):\n",
        "    mean = x.mean()\n",
        "    std = x.std() if x.std() != 0 else 1\n",
        "    return (x - mean) / std\n",
        "\n",
        "panel[feature_cols] = panel.groupby(level=0)[feature_cols].transform(zscore_transform).clip(-3, 3)\n",
        "panel = panel.dropna()\n",
        "\n",
        "print(f\"‚úÖ Features normalized: {len(panel)} clean observations\")\n",
        "\n",
        "# ============================================================================\n",
        "# 5. TRAIN-TEST SPLIT (NO DATA LEAKAGE!)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nSplitting data (no data leakage)...\")\n",
        "\n",
        "# Hold out last 60 days for testing\n",
        "split_date = panel.index.unique()[-config.TEST_DAYS]\n",
        "train_panel = panel[panel.index < split_date]\n",
        "test_panel = panel[panel.index >= split_date]\n",
        "\n",
        "print(f\"Training: {len(train_panel)} obs ({train_panel.index.min()} to {train_panel.index.max()})\")\n",
        "print(f\"Testing:  {len(test_panel)} obs ({test_panel.index.min()} to {test_panel.index.max()})\")\n",
        "\n",
        "# ============================================================================\n",
        "# 6. XGBOOST MODEL\n",
        "# ============================================================================\n",
        "\n",
        "if config.USE_XGBOOST:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TRAINING XGBOOST (Cross-Sectional Ranking)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    X_train_xgb = train_panel[feature_cols]\n",
        "    y_train_xgb = train_panel[\"Fwd_Return_21d\"]\n",
        "    X_test_xgb = test_panel[feature_cols]\n",
        "    y_test_xgb = test_panel[\"Fwd_Return_21d\"]\n",
        "\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=4,\n",
        "        learning_rate=0.05,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        verbosity=0\n",
        "    )\n",
        "\n",
        "    xgb_model.fit(X_train_xgb, y_train_xgb)\n",
        "\n",
        "    # Validate\n",
        "    xgb_train_pred = xgb_model.predict(X_train_xgb)\n",
        "    xgb_test_pred = xgb_model.predict(X_test_xgb)\n",
        "\n",
        "    train_mae_xgb = mean_absolute_error(y_train_xgb, xgb_train_pred)\n",
        "    test_mae_xgb = mean_absolute_error(y_test_xgb, xgb_test_pred)\n",
        "\n",
        "    train_dir_xgb = (np.sign(xgb_train_pred) == np.sign(y_train_xgb)).mean()\n",
        "    test_dir_xgb = (np.sign(xgb_test_pred) == np.sign(y_test_xgb)).mean()\n",
        "\n",
        "    print(f\"\\nXGBoost Performance:\")\n",
        "    print(f\"  Train MAE: {train_mae_xgb:.4f} | Test MAE: {test_mae_xgb:.4f}\")\n",
        "    print(f\"  Train Dir Acc: {train_dir_xgb:.1%} | Test Dir Acc: {test_dir_xgb:.1%}\")\n",
        "\n",
        "    # Feature importance\n",
        "    importance = pd.DataFrame({\n",
        "        'Feature': feature_cols,\n",
        "        'Importance': xgb_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(f\"\\nTop 5 Features:\")\n",
        "    print(importance.head().to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# 7. LSTM MODEL (Time-Series)\n",
        "# ============================================================================\n",
        "\n",
        "class SimpleLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(1, 32, batch_first=True, dropout=0.2)\n",
        "        self.fc = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = torch.tanh(self.fc(out[:, -1, :])) * 0.1\n",
        "        return out\n",
        "\n",
        "if config.USE_LSTM:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TRAINING LSTM (Time-Series Prediction)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    lstm_results = {}\n",
        "\n",
        "    for ticker in TICKERS: # Limit to 20 for speed\n",
        "        try:\n",
        "            ticker_data = close[ticker].dropna()\n",
        "\n",
        "            if len(ticker_data) < 200:\n",
        "                continue\n",
        "\n",
        "            # Returns\n",
        "            returns = ticker_data.pct_change().dropna().values.reshape(-1, 1)\n",
        "\n",
        "            # Scale\n",
        "            scaler = StandardScaler()\n",
        "            scaled = scaler.fit_transform(returns)\n",
        "\n",
        "            # Sequences\n",
        "            X, y = [], []\n",
        "            for i in range(config.LOOKBACK_LSTM, len(scaled)):\n",
        "                X.append(scaled[i-config.LOOKBACK_LSTM:i])\n",
        "                y.append(scaled[i])\n",
        "\n",
        "            X = torch.FloatTensor(X)\n",
        "            y = torch.FloatTensor(y)\n",
        "\n",
        "            # Split (last 60 days for test)\n",
        "            split = len(X) - config.TEST_DAYS\n",
        "            X_train = X[:split]\n",
        "            y_train = y[:split]\n",
        "            X_test = X[split:]\n",
        "            y_test = y[split:]\n",
        "\n",
        "            # Train\n",
        "            model = SimpleLSTM()\n",
        "            criterion = nn.MSELoss()\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "            for epoch in range(30):  # Quick training\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "                output = model(X_train)\n",
        "                loss = criterion(output, y_train)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # Test\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_pred = model(X_test).numpy()\n",
        "                test_actual = y_test.numpy()\n",
        "\n",
        "            test_acc = (np.sign(test_pred.flatten()) == np.sign(test_actual.flatten())).mean()\n",
        "\n",
        "            # Predict next day\n",
        "            last_seq = torch.FloatTensor(scaled[-config.LOOKBACK_LSTM:]).unsqueeze(0)\n",
        "            with torch.no_grad():\n",
        "                next_pred_scaled = model(last_seq).item()\n",
        "\n",
        "            next_pred = scaler.inverse_transform([[next_pred_scaled]])[0, 0]\n",
        "\n",
        "            lstm_results[ticker] = {\n",
        "                'prediction': next_pred,\n",
        "                'accuracy': test_acc\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n‚úÖ LSTM trained on {len(lstm_results)} stocks\")\n",
        "    avg_acc = np.mean([r['accuracy'] for r in lstm_results.values()])\n",
        "    print(f\"   Average test accuracy: {avg_acc:.1%}\")\n",
        "\n",
        "# ============================================================================\n",
        "# 8. ENSEMBLE PREDICTIONS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GENERATING ENSEMBLE PREDICTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Get latest date predictions\n",
        "latest_date = panel.index.max()\n",
        "today_panel = panel.loc[latest_date].copy()\n",
        "\n",
        "# XGBoost predictions (cross-sectional ranking)\n",
        "if config.USE_XGBOOST:\n",
        "    xgb_scores = xgb_model.predict(today_panel[feature_cols])\n",
        "    today_panel[\"XGB_Score\"] = xgb_scores\n",
        "    today_panel[\"XGB_Rank\"] = today_panel[\"XGB_Score\"].rank(ascending=False)\n",
        "else:\n",
        "    today_panel[\"XGB_Score\"] = 0\n",
        "    today_panel[\"XGB_Rank\"] = 0\n",
        "\n",
        "# LSTM predictions (time-series)\n",
        "if config.USE_LSTM:\n",
        "    lstm_scores = []\n",
        "    lstm_confidences = []\n",
        "\n",
        "    for ticker in today_panel[\"Ticker\"]:\n",
        "        if ticker in lstm_results:\n",
        "            lstm_scores.append(lstm_results[ticker]['prediction'])\n",
        "            lstm_confidences.append(lstm_results[ticker]['accuracy'])\n",
        "        else:\n",
        "            lstm_scores.append(0)\n",
        "            lstm_confidences.append(0.5)\n",
        "\n",
        "    today_panel[\"LSTM_Score\"] = lstm_scores\n",
        "    today_panel[\"LSTM_Confidence\"] = lstm_confidences\n",
        "else:\n",
        "    today_panel[\"LSTM_Score\"] = 0\n",
        "    today_panel[\"LSTM_Confidence\"] = 0.5\n",
        "\n",
        "# ENSEMBLE\n",
        "if config.USE_XGBOOST and config.USE_LSTM:\n",
        "    # Normalize scores to [0, 1]\n",
        "    xgb_norm = (today_panel[\"XGB_Score\"] - today_panel[\"XGB_Score\"].min()) / (today_panel[\"XGB_Score\"].max() - today_panel[\"XGB_Score\"].min())\n",
        "    lstm_norm = (today_panel[\"LSTM_Score\"] - today_panel[\"LSTM_Score\"].min()) / (today_panel[\"LSTM_Score\"].max() - today_panel[\"LSTM_Score\"].min())\n",
        "\n",
        "    today_panel[\"Ensemble_Score\"] = (\n",
        "        config.ENSEMBLE_WEIGHT_XGB * xgb_norm +\n",
        "        config.ENSEMBLE_WEIGHT_LSTM * lstm_norm\n",
        "    )\n",
        "    today_panel[\"Confidence\"] = today_panel[\"LSTM_Confidence\"]\n",
        "\n",
        "elif config.USE_XGBOOST:\n",
        "    today_panel[\"Ensemble_Score\"] = today_panel[\"XGB_Score\"]\n",
        "    today_panel[\"Confidence\"] = 0.6\n",
        "else:\n",
        "    today_panel[\"Ensemble_Score\"] = today_panel[\"LSTM_Score\"]\n",
        "    today_panel[\"Confidence\"] = today_panel[\"LSTM_Confidence\"]\n",
        "\n",
        "# ============================================================================\n",
        "# 9. FINAL SELECTION\n",
        "# ============================================================================\n",
        "\n",
        "# Filter by regime\n",
        "if regime.iloc[-1] == 1:\n",
        "    candidates = today_panel.copy()\n",
        "    print(\"\\nüöÄ Bull Regime: Long positions enabled\")\n",
        "else:\n",
        "    candidates = today_panel.copy()\n",
        "    print(\"\\nüêª Bear Regime: Proceed with caution\")\n",
        "\n",
        "# Filter by confidence\n",
        "candidates = candidates[candidates[\"Confidence\"] > config.MIN_CONFIDENCE]\n",
        "\n",
        "# Sort and select top N\n",
        "top_picks = candidates.sort_values(\"Ensemble_Score\", ascending=False).head(config.TOP_N)\n",
        "\n",
        "# ============================================================================\n",
        "# 10. DISPLAY RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"TOP {config.TOP_N} MOMENTUM PICKS - {datetime.now().strftime('%Y-%m-%d')}\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "display = top_picks[[\"Ticker\", \"Close\", \"Ensemble_Score\", \"XGB_Rank\", \"LSTM_Score\", \"Confidence\"]].copy()\n",
        "display[\"Ensemble_Score\"] = display[\"Ensemble_Score\"].apply(lambda x: f\"{x:.3f}\")\n",
        "display[\"LSTM_Score\"] = display[\"LSTM_Score\"].apply(lambda x: f\"{x*100:+.2f}%\")\n",
        "display[\"Confidence\"] = display[\"Confidence\"].apply(lambda x: f\"{x:.1%}\")\n",
        "display.columns = [\"Ticker\", \"Price\", \"Ensemble\", \"XGB_Rank\", \"LSTM_Pred\", \"Confidence\"]\n",
        "\n",
        "print(display.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL CONTRIBUTIONS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"XGBoost weight:  {config.ENSEMBLE_WEIGHT_XGB:.0%} (cross-sectional ranking)\")\n",
        "print(f\"LSTM weight:     {config.ENSEMBLE_WEIGHT_LSTM:.0%} (time-series prediction)\")\n",
        "print(f\"Ensemble method: Weighted average of normalized scores\")\n",
        "\n",
        "if config.USE_XGBOOST and config.USE_LSTM:\n",
        "    print(f\"\\nüí° Strategy: XGBoost selects stocks, LSTM confirms timing\")\n",
        "elif config.USE_XGBOOST:\n",
        "    print(f\"\\nüí° Strategy: Pure XGBoost cross-sectional momentum\")\n",
        "else:\n",
        "    print(f\"\\nüí° Strategy: Pure LSTM time-series prediction\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# 11. SAVE RESULTS\n",
        "# ============================================================================\n",
        "\n",
        "output_file = 'ensemble_predictions.csv'\n",
        "top_picks.to_csv(output_file)\n",
        "print(f\"üìÅ Results saved to: {output_file}\\n\")"
      ]
    }
  ]
}